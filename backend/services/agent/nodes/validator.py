import json
from typing import Any, Dict
from core.logging_config import get_logger
from services.agent.nodes.base import NodeAbstractClass
from services.guardrails_manager import GuardrailsManager
from schemas.room_info import RoomData
from utils.get_prompts import compile_prompt


logger = get_logger(__name__)

FALLBACK_RESPONSE = "I apologize, but I am unable to provide a helpful response at this time. Please try rephrasing your request or asking about a different topic."

class ValidationNode(NodeAbstractClass):
    """
    A node that validates the response generated by another node (e.g., SeniorNode)
    to ensure it meets quality and safety standards before being sent to the user. It
    uses NeMo Guardrails for robust, configurable validation.
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.guardrails = GuardrailsManager()

    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Evaluates the generated answer against NeMo Guardrails.

        If the answer passes validation, it's passed through. If it's blocked or
        modified by the guardrails, the node can trigger a retry or substitute a
        safe, generic fallback response.

        Args:
            state (dict): The current graph state, expected to contain:
                          - 'answer': The response to be validated.
                          - 'question': The original user question for context.

        Returns:
            dict: The updated state with either the validated 'answer' or a fallback,
                  and instructions for the next node.
        """
        logger.info("---VALIDATING RESPONSE WITH GUARDRAILS---")
        original_answer = state.get("answer", "")
        summary = state.get("conversation_summary", "")
        question = state.get("question", "")
        room_details: RoomData = state.get("room_details")
        personalize_agent = state.get("personalize_agent", "")
        personality = personalize_agent.get("personality", "").lower().strip()

        # if not original_answer:
        #     logger.warning("No answer found to validate. Returning fallback.")
        #     return {"answer": FALLBACK_RESPONSE, "next_node": "__end__"}

        # The check for guardrails initialization is now handled inside the manager.

        try:
            
            agent_to_execute = [agent for agent in room_details.agents if agent.id == personalize_agent.get("id", "")][0]

            if not agent_to_execute:
                logger.error(f"Could not find agent with ID {personalize_agent.get('id', '')} to refine speech.")
                return {"answer": original_answer}

            # Extract agent details
            agent_name = agent_to_execute.name
            dedication = agent_to_execute.dedication
            qualities = agent_to_execute.qualities
            communication_style = agent_to_execute.communication_style
            tone = agent_to_execute.tone
            emoji_usage = agent_to_execute.emoji_usage
            country = agent_to_execute.country
            
            agent_personality = (
                f"Agent Name: {agent_name}\n"
                f"Agent Country: {country}\n"
                f"Agent Dedication: {dedication}\n"
                f"Agent Qualities: {qualities}\n"
                f"Agent Communication Style: {communication_style}\n"
                f"Agent Tone: {tone}\n"
                f"Agent Emoji Usage: {emoji_usage}\n"
            )

            dynamic_rules = []
            if room_details and hasattr(room_details, 'room') and hasattr(room_details.room, 'rules'):
                dynamic_rules = room_details.room.rules
                
            rules_text_parts = []
            for rule in dynamic_rules:
                # The description can have multiple lines. We must preserve them.
                # Replacing colons is a good practice to avoid potential syntax conflicts.
                description = rule.description.replace(':', '. ')
                rules_text_parts.append(f"- {rule.name}: {description}")
            
            raw_rules_block = "\n\n".join(rules_text_parts)

            # is_valid, final_answer = await self.guardrails.validate_response(
            #     question=summary,
            #     answer=original_answer,
            #     context=summary,
            #     dynamic_rules=dynamic_rules,
            #     llm_manager=self.llm_manager
            # )
            
            prompt_template = await compile_prompt(
                "compliance_evaluator",
                agent_personality=agent_personality,
                agent_answer=original_answer,
                group_rules=raw_rules_block,
            )
            
            
            validation_answer = await self.llm_manager.ainvoke(prompt=prompt_template)
            
            try:
                decision_clean = validation_answer.strip('`').split('\n', 1)[1].rsplit('\n', 1)[0]
                json_response = json.loads(decision_clean)
            except json.JSONDecodeError:
                try:
                    decision_clean = validation_answer
                    json_response = json.loads(validation_answer)
                except json.JSONDecodeError:
                    try:
                        decision_clean = validation_answer.strip('`').split('\n', 1)[1].rsplit('\n', 1)[0]
                        fixed_string = decision_clean.replace('\n', '')
                        fixed_string = fixed_string.replace('\u00a0', ' ')
                        json_response = json.loads(fixed_string)
                    except:
                        logger.warning(f"Failed to parse JSON from guardrails validation. Response: '{validation_answer}'")
                        return {"answer": original_answer}
            
            if json_response["complies"].lower() == "yes":
                logger.info("Guardrails validation: PASSED.")
                return {"answer": original_answer}
            
            else:
                logger.warning("Guardrails validation: REJECTED/MODIFIED.")
                final_answer = json_response.get("agent_answer", "")
                logger.info(f"Final Answer after Guardrails: {final_answer}")
                return {"answer": final_answer}

            # if is_valid:
            #     logger.info("Guardrails validation: PASSED. Finalizing.")
            #     return {"answer": final_answer, "next_node": "__end__"}
            # else:
            #     # The response was blocked or modified by a guardrail.
            #     source_node = state.get("source_node_for_validation")
            #     logger.warning(f"Guardrails validation: REJECTED/MODIFIED. Source: {source_node}. Retrying.")

            #     retries = state.get("validation_retries", 0)
            #     if retries > 1:
            #         logger.error("Max validation retries reached. Using fallback response and ending.")
            #         # Use the (potentially modified) answer from guardrails if it's not empty,
            #         # otherwise use the generic fallback.
            #         final_response = final_answer if final_answer else FALLBACK_RESPONSE
            #         return {"answer": final_response, "next_node": "__end__"}

            #     if not source_node or source_node not in ["junior", "senior"]:
            #         logger.error(f"Invalid or missing source node ('{source_node}') for retry. Using fallback.")
            #         return {"answer": FALLBACK_RESPONSE, "next_node": "__end__"}

            #     return {
            #         "answer": "",  # Clear the answer to force regeneration
            #         "validation_retries": retries + 1,
            #         "next_node": source_node
            #     }
        except Exception as err:
            logger.error(f"An error occurred during Guardrails validation: {err}. Using fallback response.")
            return {"answer": original_answer}